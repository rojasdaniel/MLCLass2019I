El paper realiza una revisión de algoritmos de clasificación sobre un set de datos robusto (86 datasets de UCI machine learning data base) con el fin de identificar el comportamiento de múltiples clasificadores sin buscar desprestigiar unos sobre otros o proponer uno nuevo que sea significativamente mejor que los comúnmente utilizados. El autor del documento recalca la necesidad de reconocer que algunos clasificadores pueden tener mejor performance que otros sobre un determinado set de datos y precisamente lo que el documento quiere proponer una manera de calificar el rendimiento de los clasificadores teniendo presente que en algunos existe una previa experiencia de manejo sobre otros que pueden ser del no-dominio de los autores del documento por lo que paquetes como Caret de R que automáticamente ajustan los parámetros puede servir para balancear la calificación de estos. Se utilizaron 179 clasificadores y un total de 121 datasets dando 21659 combinaciones entre los clasificadores y los set de datos, utilizando subdivisiones de sets de entrenamiento y prueba generados aleatoriamente para dar con el resultado de que los algoritmos construidos con base en Random Forest (parRF_t) con una precisión de 82% como los mejores clasificadores detectados seguidos del algoritmo rf_t (random forest ajustado por el paquete caret de R y de tercer lugar el algoritmo de support vector machine svm_C. Adicionalmente se propone calcular para cada clasificador la Probabilidad de Lograr la Máxima Predicción (PAMA por las siglas en ingles) para un data set dado, esta métrica calcula el número de datasets máximo para que un clasificador alcance su máximo rendimiento en donde los algoritmos basados en Random Forest logran conseguir el máximo puntaje con un porcentaje PAMA superior al 90%.